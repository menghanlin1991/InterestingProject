{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import uuid\n",
    "from fake_useragent import UserAgent\n",
    "import jieba\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from scipy.misc import imread\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather Basic Data using Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uuid():\n",
    "    return str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaGouSpider():\n",
    "    ua = UserAgent()\n",
    "    cookie = 'JSESSIONID=' + get_uuid() + ';' + \\\n",
    "    'user_trace_token=' + get_uuid() + '; LGUID=' + get_uuid() + '; index_location_city=%E6%88%90%E9%83%BD;' + \\\n",
    "    'SEARCH_ID=' + get_uuid() + '; _gid=GA1.2.717841549.1514043316;' +  \\\n",
    "    '_ga=GA1.2.952298646.1514043316;'\\\n",
    "    'LGSID=' + get_uuid() + ';' +  \\\n",
    "    'LGRID=' + get_uuid() + ';'\n",
    "    headers = {'cookie': cookie,\\\n",
    "               'user-agent': ua.random,\\\n",
    "               'origin': \"https://www.lagou.com\",\\\n",
    "               'Host':'www.lagou.com',\\\n",
    "               'x-anit-forge-code': \"0\",\\\n",
    "               'x-requested-with': \"XMLHttpRequest\",\\\n",
    "               'x-anit-forge-token': \"None\",\\\n",
    "               'accept': \"application/json, text/javascript, */*; q=0.01\",\\\n",
    "               'accept-encoding': \"gzip, deflate, br\",\\\n",
    "               'accept-language': \"zh-CN,zh;q=0.8,en;q=0.6\",\\\n",
    "               'content-type': \"application/x-www-form-urlencoded; charset=UTF-8\",\\\n",
    "               'Referer':'https://www.lagou.com/jobs/list_python?labelWords=&fromSearch=true&suginput=',\\\n",
    "               'cache-control': \"no-cache\",\\\n",
    "               'postman-token': \"91beb456-8dd9-0390-a3a5-64ff3936fa63\"}\n",
    "    def __init__(self, city = '北京', keyword = '数据分析', page_num = 1):\n",
    "        self.para = {  \n",
    "            'first': 'true',  \n",
    "            'pn': '1',  \n",
    "            'kd': keyword,  \n",
    "            'city': city\n",
    "            }\n",
    "        self.page_num = page_num\n",
    "        self.proxies = {'http':'http://119.28.142.148:8888',\\\n",
    "            'https':'https://119.28.142.148:8888'}\n",
    "    def spider(self):\n",
    "        position_list = []\n",
    "        try: \n",
    "            for pn_loop in range(0, self.page_num+1):\n",
    "                print('{:d} begins'.format(pn_loop) )\n",
    "                if pn_loop == 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    self.para['first'] = 'False'\n",
    "                    self.para['pn'] = str(pn_loop)\n",
    "                response = requests.get('https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false&isSchoolJob=0',\n",
    "                       headers=headers, params=self.para, proxies = self.proxies)\n",
    "                response_json = response.json()\n",
    "                print(response_json)\n",
    "                position_inf = response_json['content']['positionResult']['result']\n",
    "                position_list.extend(position_inf)\n",
    "                time.sleep(np.random.randint(5,10))\n",
    "        except:\n",
    "            print('Someting wrong here')\n",
    "        return position_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fenxi_spider = LaGouSpider(city = '北京', keyword = '数据分析', page_num = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "#position_list = fenxi_spider.spider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(position_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wajue_spider = LaGouSpider(city = '北京', keyword = '数据挖掘', page_num = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "#position_list_wajue = wajue_spider.spider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(position_list_wajue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save part of Data to DataFrame using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectData():\n",
    "    def __init__(self, position_list):\n",
    "        self.position_list = position_list\n",
    "    def select_data(self):\n",
    "        data = pd.DataFrame()\n",
    "        for loop in range(len(self.position_list)):\n",
    "            data.loc[loop, 'city'] = self.position_list[loop]['city']\n",
    "            data.loc[loop, 'companyFullName'] = self.position_list[loop]['companyFullName']\n",
    "            data.loc[loop, 'companyShortName'] = self.position_list[loop]['companyShortName']\n",
    "            data.loc[loop, 'companySize'] = self.position_list[loop]['companySize']\n",
    "            data.loc[loop, 'district'] = self.position_list[loop]['district']\n",
    "            data.loc[loop, 'education'] = self.position_list[loop]['education']\n",
    "            data.loc[loop, 'financeStage'] = self.position_list[loop]['financeStage']\n",
    "            data.loc[loop, 'positionName'] = self.position_list[loop]['positionName']\n",
    "            data.loc[loop, 'salary'] = self.position_list[loop]['salary']\n",
    "            data.loc[loop, 'workYear'] = self.position_list[loop]['workYear']\n",
    "            data.loc[loop, 'positionId'] = self.position_list[loop]['positionId']\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_fenxi = SelectData(position_list)\n",
    "#data_fenxi = data_fenxi.select_data()\n",
    "#data_fenxi['positionId'] = data_fenxi.positionId.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_fenxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_fenxi.to_csv('shujufenxi_basic.csv', encoding=\"utf_8_sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(data_fenxi.positionId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_wajue = SelectData(position_list_wajue)\n",
    "#data_wajue = data_wajue.select_data()\n",
    "#data_wajue['positionId'] = data_wajue.positionId.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_wajue.to_csv('shujuwajue_basic.csv', encoding=\"utf_8_sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_wajue.positionId.drop_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather more Detailed Data based on PositionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrawlDetail():\n",
    "    headers = {  \n",
    "        'Host':'www.lagou.com',  \n",
    "        'Upgrade-Insecure-Requests':'1',  \n",
    "        'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.119 Safari/537.36'  \n",
    "    }  \n",
    "    def __init__(self, positionId_list):\n",
    "        self.positionId_list = positionId_list\n",
    "    def crawl(self):\n",
    "        data_detail = pd.DataFrame()\n",
    "        max_retry = 8\n",
    "        for index, positionId in enumerate(self.positionId_list):\n",
    "            print(positionId)\n",
    "            # the first try\n",
    "            url = 'https://www.lagou.com/jobs/%s.html' %positionId\n",
    "            response = requests.get(url, headers = headers)\n",
    "            soup = BeautifulSoup(response.content, 'html.parser') \n",
    "            if soup.find('dd', attrs={'class':'job_bt'}) == None: # the first try fail\n",
    "                print ('the first try fail')\n",
    "                none_flag = True\n",
    "                retry_num = 0\n",
    "                data_detail.loc[index, 'positionId'] = self.positionId_list[index]\n",
    "                while ((none_flag == True) & (retry_num < max_retry)):\n",
    "                    #print ('retry again')\n",
    "                    retry_num += 1\n",
    "                    response = requests.get(url, headers = headers)\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    if soup.find('dd', attrs={'class':'job_bt'}) == None:\n",
    "                        none_flag = True\n",
    "                        time.sleep(5)\n",
    "                    else:\n",
    "                        print('retry {:d} times, {:d}'.format(retry_num, positionId))\n",
    "                        none_flag = False \n",
    "                        data_detail.loc[index, 'detail'] = soup.find('dd', attrs={'class':'job_bt'}).text    \n",
    "                if retry_num == max_retry:\n",
    "                    data_detail.loc[index, 'detail'] = None\n",
    "            else: # the first try succeed \n",
    "                print ('the first try succeed')\n",
    "                data_detail.loc[index, 'positionId'] = self.positionId_list[index]\n",
    "                data_detail.loc[index, 'detail'] = soup.find('dd', attrs={'class':'job_bt'}).text\n",
    "            sleep_random = np.random.randint(5,10)\n",
    "            time.sleep(sleep_random)\n",
    "        return data_detail     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fenxi_crawl_detail = CrawlDetail(list(data_fenxi.positionId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_fenxi_detail = fenxi_crawl_detail.crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data_fenxi_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wajue_crawl_detail = CrawlDetail(list(data_wajue.positionId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_wajue_detail = wajue_crawl_detail.crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(data_wajue_detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_fenxi_detail.to_csv('shujufenxi_detail.csv', encoding=\"utf_8_sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_wajue_detail.to_csv('shujuwajue_detail.csv', encoding=\"utf_8_sig\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fenxi = pd.read_csv('shujufenxi_basic.csv')\n",
    "data_wajue = pd.read_csv('shujuwajue_basic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fenxi_detail = pd.read_csv('shujufenxi_detail.csv')\n",
    "data_wajue_detail = pd.read_csv('shujuwajue_detail.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess \n",
    "- merge detail inf\n",
    "- add one column to both fenxi and wajue to seperate the '数据分析' and ‘数据入门’\n",
    "- since re-crawl part of wajue data, drop the duplicated ones\n",
    "- merge fenxi and wajue data together\n",
    "- reset index for the data_all\n",
    "- save data_all to csv file\n",
    "\n",
    "## Clean \n",
    "- copy data_all for cleanning\n",
    "- drop positonName column since we have kd column\n",
    "- delete the '\\n' in detail column\n",
    "- (ing) split the detail column to seperate part, e.g., 工作职责，任职要求\n",
    "- not good the split part, keep the sub data to dig currently, if there's time later, revise\n",
    "- add salary_avg column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- merge detail inf and add one column to both fenxi and wajue to seperate the '数据分析' and ‘数据入门’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fenxi_all = pd.merge(data_fenxi, data_fenxi_detail, on='positionId')\n",
    "data_fenxi_all['kd'] = 'fenxi'\n",
    "len(data_fenxi_all)\n",
    "data_fenxi_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_fenxi_all = data_fenxi_all.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wajue_all = pd.merge(data_wajue, data_wajue_detail, on='positionId')\n",
    "len(data_wajue_all)\n",
    "data_wajue_all['kd'] = 'wajue'\n",
    "data_wajue_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_wajue_all = data_wajue_all.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- re-crawl part of wajue data, drop the duplicated ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wajue_all = data_wajue_all.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_wajue_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- merge fenxi and wajue data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.concat([data_fenxi_all, data_wajue_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>companyFullName</th>\n",
       "      <th>companyShortName</th>\n",
       "      <th>companySize</th>\n",
       "      <th>district</th>\n",
       "      <th>education</th>\n",
       "      <th>financeStage</th>\n",
       "      <th>positionName</th>\n",
       "      <th>salary</th>\n",
       "      <th>workYear</th>\n",
       "      <th>positionId</th>\n",
       "      <th>detail</th>\n",
       "      <th>kd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>北京</td>\n",
       "      <td>汇联金科信息技术（北京 )有限公司</td>\n",
       "      <td>汇联金科</td>\n",
       "      <td>50-150人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>A轮</td>\n",
       "      <td>数据分析师</td>\n",
       "      <td>10k-15k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4295741</td>\n",
       "      <td>\\n职位描述：\\n\\n工作职责：1. 根据业务实际需求，制定相应策略，完成深入的运营数据分析...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>北京</td>\n",
       "      <td>途家网网络技术（北京）有限公司</td>\n",
       "      <td>途家网</td>\n",
       "      <td>500-2000人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>D轮及以上</td>\n",
       "      <td>数据分析师</td>\n",
       "      <td>15k-30k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4505031</td>\n",
       "      <td>\\n职位描述：\\n\\n工作职责：1、通过SQL收集数据，分析流量、活动、订单等核心数据，形成...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>北京</td>\n",
       "      <td>和信电子商务有限公司</td>\n",
       "      <td>和信贷</td>\n",
       "      <td>150-500人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>大专</td>\n",
       "      <td>上市公司</td>\n",
       "      <td>数据分析师</td>\n",
       "      <td>6k-8k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4507358</td>\n",
       "      <td>\\n职位描述：\\n\\n\\n岗位职责：\\n1. 对数据敏感，善于发现业务中存在的问题，并给出优...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>北京</td>\n",
       "      <td>京东金融</td>\n",
       "      <td>京东金融</td>\n",
       "      <td>2000人以上</td>\n",
       "      <td>大兴区</td>\n",
       "      <td>本科</td>\n",
       "      <td>上市公司</td>\n",
       "      <td>数据分析师</td>\n",
       "      <td>14k-27k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4505903</td>\n",
       "      <td>\\n职位描述：\\n\\n职责描述：\\n1、负责定期编制金融集团合并报表，完成报表变动分析；  ...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>北京</td>\n",
       "      <td>杭州云脑科技有限公司</td>\n",
       "      <td>云脑科技</td>\n",
       "      <td>15-50人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>A轮</td>\n",
       "      <td>数据分析师</td>\n",
       "      <td>15k-30k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>3898857</td>\n",
       "      <td>\\n职位描述：\\n\\n【岗位职责】\\n1、收集和整理公司运营数据、竞品数据、行业数据，解读趋...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city    companyFullName companyShortName companySize district education  \\\n",
       "0   北京  汇联金科信息技术（北京 )有限公司             汇联金科     50-150人      朝阳区        本科   \n",
       "1   北京    途家网网络技术（北京）有限公司              途家网   500-2000人      朝阳区        本科   \n",
       "2   北京         和信电子商务有限公司              和信贷    150-500人      朝阳区        大专   \n",
       "3   北京               京东金融             京东金融     2000人以上      大兴区        本科   \n",
       "4   北京         杭州云脑科技有限公司             云脑科技      15-50人      朝阳区        本科   \n",
       "\n",
       "  financeStage positionName   salary workYear positionId  \\\n",
       "0           A轮        数据分析师  10k-15k     3-5年    4295741   \n",
       "1        D轮及以上        数据分析师  15k-30k     3-5年    4505031   \n",
       "2         上市公司        数据分析师    6k-8k     3-5年    4507358   \n",
       "3         上市公司        数据分析师  14k-27k     3-5年    4505903   \n",
       "4           A轮        数据分析师  15k-30k     3-5年    3898857   \n",
       "\n",
       "                                              detail     kd  \n",
       "0  \\n职位描述：\\n\\n工作职责：1. 根据业务实际需求，制定相应策略，完成深入的运营数据分析...  fenxi  \n",
       "1  \\n职位描述：\\n\\n工作职责：1、通过SQL收集数据，分析流量、活动、订单等核心数据，形成...  fenxi  \n",
       "2  \\n职位描述：\\n\\n\\n岗位职责：\\n1. 对数据敏感，善于发现业务中存在的问题，并给出优...  fenxi  \n",
       "3  \\n职位描述：\\n\\n职责描述：\\n1、负责定期编制金融集团合并报表，完成报表变动分析；  ...  fenxi  \n",
       "4  \\n职位描述：\\n\\n【岗位职责】\\n1、收集和整理公司运营数据、竞品数据、行业数据，解读趋...  fenxi  "
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reset index for the data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.to_csv('data_all.csv', encoding=\"utf_8_sig\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv('data_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>companyFullName</th>\n",
       "      <th>companyShortName</th>\n",
       "      <th>companySize</th>\n",
       "      <th>district</th>\n",
       "      <th>education</th>\n",
       "      <th>financeStage</th>\n",
       "      <th>positionName</th>\n",
       "      <th>salary</th>\n",
       "      <th>workYear</th>\n",
       "      <th>positionId</th>\n",
       "      <th>detail</th>\n",
       "      <th>kd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>北京</td>\n",
       "      <td>汇联金科信息技术（北京 )有限公司</td>\n",
       "      <td>汇联金科</td>\n",
       "      <td>50-150人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>A轮</td>\n",
       "      <td>数据分析师</td>\n",
       "      <td>10k-15k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4295741</td>\n",
       "      <td>\\n职位描述：\\n\\n工作职责：1. 根据业务实际需求，制定相应策略，完成深入的运营数据分析...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>北京</td>\n",
       "      <td>途家网网络技术（北京）有限公司</td>\n",
       "      <td>途家网</td>\n",
       "      <td>500-2000人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>D轮及以上</td>\n",
       "      <td>数据分析师</td>\n",
       "      <td>15k-30k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4505031</td>\n",
       "      <td>\\n职位描述：\\n\\n工作职责：1、通过SQL收集数据，分析流量、活动、订单等核心数据，形成...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>北京</td>\n",
       "      <td>和信电子商务有限公司</td>\n",
       "      <td>和信贷</td>\n",
       "      <td>150-500人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>大专</td>\n",
       "      <td>上市公司</td>\n",
       "      <td>数据分析师</td>\n",
       "      <td>6k-8k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4507358</td>\n",
       "      <td>\\n职位描述：\\n\\n\\n岗位职责：\\n1. 对数据敏感，善于发现业务中存在的问题，并给出优...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>北京</td>\n",
       "      <td>京东金融</td>\n",
       "      <td>京东金融</td>\n",
       "      <td>2000人以上</td>\n",
       "      <td>大兴区</td>\n",
       "      <td>本科</td>\n",
       "      <td>上市公司</td>\n",
       "      <td>数据分析师</td>\n",
       "      <td>14k-27k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4505903</td>\n",
       "      <td>\\n职位描述：\\n\\n职责描述：\\n1、负责定期编制金融集团合并报表，完成报表变动分析；  ...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>北京</td>\n",
       "      <td>杭州云脑科技有限公司</td>\n",
       "      <td>云脑科技</td>\n",
       "      <td>15-50人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>A轮</td>\n",
       "      <td>数据分析师</td>\n",
       "      <td>15k-30k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>3898857</td>\n",
       "      <td>\\n职位描述：\\n\\n【岗位职责】\\n1、收集和整理公司运营数据、竞品数据、行业数据，解读趋...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city    companyFullName companyShortName companySize district education  \\\n",
       "0   北京  汇联金科信息技术（北京 )有限公司             汇联金科     50-150人      朝阳区        本科   \n",
       "1   北京    途家网网络技术（北京）有限公司              途家网   500-2000人      朝阳区        本科   \n",
       "2   北京         和信电子商务有限公司              和信贷    150-500人      朝阳区        大专   \n",
       "3   北京               京东金融             京东金融     2000人以上      大兴区        本科   \n",
       "4   北京         杭州云脑科技有限公司             云脑科技      15-50人      朝阳区        本科   \n",
       "\n",
       "  financeStage positionName   salary workYear  positionId  \\\n",
       "0           A轮        数据分析师  10k-15k     3-5年     4295741   \n",
       "1        D轮及以上        数据分析师  15k-30k     3-5年     4505031   \n",
       "2         上市公司        数据分析师    6k-8k     3-5年     4507358   \n",
       "3         上市公司        数据分析师  14k-27k     3-5年     4505903   \n",
       "4           A轮        数据分析师  15k-30k     3-5年     3898857   \n",
       "\n",
       "                                              detail     kd  \n",
       "0  \\n职位描述：\\n\\n工作职责：1. 根据业务实际需求，制定相应策略，完成深入的运营数据分析...  fenxi  \n",
       "1  \\n职位描述：\\n\\n工作职责：1、通过SQL收集数据，分析流量、活动、订单等核心数据，形成...  fenxi  \n",
       "2  \\n职位描述：\\n\\n\\n岗位职责：\\n1. 对数据敏感，善于发现业务中存在的问题，并给出优...  fenxi  \n",
       "3  \\n职位描述：\\n\\n职责描述：\\n1、负责定期编制金融集团合并报表，完成报表变动分析；  ...  fenxi  \n",
       "4  \\n职位描述：\\n\\n【岗位职责】\\n1、收集和整理公司运营数据、竞品数据、行业数据，解读趋...  fenxi  "
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- copy data for cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_clean = data_all.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- drop positonName column since we have kd column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_clean.drop('positionName', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- delete the '\\n' in detail column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_clean['detail'] = data_all_clean['detail'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>companyFullName</th>\n",
       "      <th>companyShortName</th>\n",
       "      <th>companySize</th>\n",
       "      <th>district</th>\n",
       "      <th>education</th>\n",
       "      <th>financeStage</th>\n",
       "      <th>salary</th>\n",
       "      <th>workYear</th>\n",
       "      <th>positionId</th>\n",
       "      <th>detail</th>\n",
       "      <th>kd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>北京</td>\n",
       "      <td>完美世界（北京）软件科技发展有限公司</td>\n",
       "      <td>完美世界</td>\n",
       "      <td>2000人以上</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>上市公司</td>\n",
       "      <td>18k-30k</td>\n",
       "      <td>1-3年</td>\n",
       "      <td>4323681</td>\n",
       "      <td>职位描述：工作职责：1) 参与数据清洗，大数据处理，数据挖掘相关工作 2) 参与各种核心搜索...</td>\n",
       "      <td>wajue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>北京</td>\n",
       "      <td>飞驰镁物（北京）信息服务有限公司</td>\n",
       "      <td>飞驰镁物</td>\n",
       "      <td>150-500人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>B轮</td>\n",
       "      <td>13k-20k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>3466215</td>\n",
       "      <td>职位描述：岗位职责：1. 负责数据挖掘分析需求的沟通、收集、整理、理解和实现；2. 负责产品...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>北京</td>\n",
       "      <td>北京慢点生活科技有限公司</td>\n",
       "      <td>动动</td>\n",
       "      <td>15-50人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>B轮</td>\n",
       "      <td>15k-25k</td>\n",
       "      <td>不限</td>\n",
       "      <td>1986051</td>\n",
       "      <td>职位描述：【我们的动动情怀】我们是慢点科技荣誉出品的动动/Pacer，我们致力于用技术的手段...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>北京</td>\n",
       "      <td>北京国双科技有限公司</td>\n",
       "      <td>Gridsum 国双</td>\n",
       "      <td>500-2000人</td>\n",
       "      <td>海淀区</td>\n",
       "      <td>本科</td>\n",
       "      <td>上市公司</td>\n",
       "      <td>15k-30k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>920876</td>\n",
       "      <td>职位描述：在国双数据中心，你可以领略国内外数据行业激动人心的商业应用，拥有与全球高端客户并肩...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>北京</td>\n",
       "      <td>随行付支付有限公司</td>\n",
       "      <td>随行付支付有限公司</td>\n",
       "      <td>500-2000人</td>\n",
       "      <td>石景山区</td>\n",
       "      <td>本科</td>\n",
       "      <td>上市公司</td>\n",
       "      <td>20k-30k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4042512</td>\n",
       "      <td>职位描述：岗位职责：1、支付业务的相关数据梳理；2、对业务各环节产生的数据，做统计与深度运营...</td>\n",
       "      <td>fenxi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city     companyFullName companyShortName companySize district education  \\\n",
       "535   北京  完美世界（北京）软件科技发展有限公司             完美世界     2000人以上      朝阳区        本科   \n",
       "34    北京    飞驰镁物（北京）信息服务有限公司             飞驰镁物    150-500人      朝阳区        本科   \n",
       "375   北京        北京慢点生活科技有限公司               动动      15-50人      朝阳区        本科   \n",
       "81    北京          北京国双科技有限公司       Gridsum 国双   500-2000人      海淀区        本科   \n",
       "6     北京           随行付支付有限公司        随行付支付有限公司   500-2000人     石景山区        本科   \n",
       "\n",
       "    financeStage   salary workYear  positionId  \\\n",
       "535         上市公司  18k-30k     1-3年     4323681   \n",
       "34            B轮  13k-20k     3-5年     3466215   \n",
       "375           B轮  15k-25k       不限     1986051   \n",
       "81          上市公司  15k-30k     3-5年      920876   \n",
       "6           上市公司  20k-30k     3-5年     4042512   \n",
       "\n",
       "                                                detail     kd  \n",
       "535  职位描述：工作职责：1) 参与数据清洗，大数据处理，数据挖掘相关工作 2) 参与各种核心搜索...  wajue  \n",
       "34   职位描述：岗位职责：1. 负责数据挖掘分析需求的沟通、收集、整理、理解和实现；2. 负责产品...  fenxi  \n",
       "375  职位描述：【我们的动动情怀】我们是慢点科技荣誉出品的动动/Pacer，我们致力于用技术的手段...  fenxi  \n",
       "81   职位描述：在国双数据中心，你可以领略国内外数据行业激动人心的商业应用，拥有与全球高端客户并肩...  fenxi  \n",
       "6    职位描述：岗位职责：1、支付业务的相关数据梳理；2、对业务各环节产生的数据，做统计与深度运营...  fenxi  "
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_clean.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'职位描述：工作职责：1. 根据业务实际需求，制定相应策略，完成深入的运营数据分析报告，对用户活跃、留存、有效行为等指标负责；2. 对运营数据进行分析与监控，能够基于数据进行用户画像描绘、用户分层，并针对不同用户指定不同的运营策略，拉新、促活；3. 统计分析相关业务数据，敏锐地发现异常，针对风险点进行持续追踪与预警；4、结合行业数据、业界观点和市场趋势，为长期业务发展方向提供战略层面的意见和建议任职要求：1. 本科及以上学历，经济、统计、数学、计算机等相关专业背景优先；2. 至少3年以上互联网金融行业用户研究、数据分析、数据运营、数据挖掘等相关经验；3 具备优秀的数据分析能力及策略制定能力，能够快速理解业务，有独立思考能力并提出自己的见解；4. 对数据敏感，能从海量数据提炼核心结果，具备优秀的数据处理能力、报告呈现于解说能力；5. 沟通能力强，具备一定的抗压性6.\\xa0熟练使用Excel，包括图表制作，函数及数据透视表运用等。熟练使用数理统计、数据分析、数据挖掘工具软件（如SPSS，SAS,Clementine 等）。精通数据分析方法：回归，时间序列，神经网络，聚类分析，关联分析，数据建模等分析方法'"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_clean['detail'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- split the detail column to seperate part, i.e., 工作职责，任职要求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "list1 = data_all_clean[pd.isna(data_all_clean['detail'].str.extract('(1.*)1.*'))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "list2 = data_all_clean[pd.isna(data_all_clean['detail'].str.extract('1.*(1.*)'))].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list1) == set(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_all_clean['task'] = data_all_clean['detail'].str.extract('(1.*)1.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_all_clean['skill'] = data_all_clean['detail'].str.extract('1.*(1.*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>companyFullName</th>\n",
       "      <th>companyShortName</th>\n",
       "      <th>companySize</th>\n",
       "      <th>district</th>\n",
       "      <th>education</th>\n",
       "      <th>financeStage</th>\n",
       "      <th>salary</th>\n",
       "      <th>workYear</th>\n",
       "      <th>positionId</th>\n",
       "      <th>detail</th>\n",
       "      <th>kd</th>\n",
       "      <th>task</th>\n",
       "      <th>skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>北京</td>\n",
       "      <td>汇联金科信息技术（北京 )有限公司</td>\n",
       "      <td>汇联金科</td>\n",
       "      <td>50-150人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>A轮</td>\n",
       "      <td>10k-15k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4295741</td>\n",
       "      <td>职位描述：工作职责：1. 根据业务实际需求，制定相应策略，完成深入的运营数据分析报告，对用户...</td>\n",
       "      <td>fenxi</td>\n",
       "      <td>1. 根据业务实际需求，制定相应策略，完成深入的运营数据分析报告，对用户活跃、留存、有效行为...</td>\n",
       "      <td>1. 本科及以上学历，经济、统计、数学、计算机等相关专业背景优先；2. 至少3年以上互联网金...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>北京</td>\n",
       "      <td>途家网网络技术（北京）有限公司</td>\n",
       "      <td>途家网</td>\n",
       "      <td>500-2000人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>D轮及以上</td>\n",
       "      <td>15k-30k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4505031</td>\n",
       "      <td>职位描述：工作职责：1、通过SQL收集数据，分析流量、活动、订单等核心数据，形成可视化报表；...</td>\n",
       "      <td>fenxi</td>\n",
       "      <td>1、通过SQL收集数据，分析流量、活动、订单等核心数据，形成可视化报表；2、分析用户行为、特...</td>\n",
       "      <td>1、3年以上互联网数据经验2、逻辑能力强，擅长数据分析与需求调研3、有很强的数据调研分析能力...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>北京</td>\n",
       "      <td>和信电子商务有限公司</td>\n",
       "      <td>和信贷</td>\n",
       "      <td>150-500人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>大专</td>\n",
       "      <td>上市公司</td>\n",
       "      <td>6k-8k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4507358</td>\n",
       "      <td>职位描述：岗位职责：1. 对数据敏感，善于发现业务中存在的问题，并给出优化建议；2.熟悉用户...</td>\n",
       "      <td>fenxi</td>\n",
       "      <td>1. 对数据敏感，善于发现业务中存在的问题，并给出优化建议；2.熟悉用户生命周期管理建设，搭...</td>\n",
       "      <td>1、 金融、统计、数学、计算机等专业优先；2、 熟练使用Excel、SQL、SPSS，能够使...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>北京</td>\n",
       "      <td>京东金融</td>\n",
       "      <td>京东金融</td>\n",
       "      <td>2000人以上</td>\n",
       "      <td>大兴区</td>\n",
       "      <td>本科</td>\n",
       "      <td>上市公司</td>\n",
       "      <td>14k-27k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4505903</td>\n",
       "      <td>职位描述：职责描述：1、负责定期编制金融集团合并报表，完成报表变动分析；          ...</td>\n",
       "      <td>fenxi</td>\n",
       "      <td>1、负责定期编制金融集团合并报表，完成报表变动分析；                    ...</td>\n",
       "      <td>1、计算机、统计学、数学、数理统计等相关专业，本科以上学历，3年以上相关工作经验； 2、熟练...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>北京</td>\n",
       "      <td>杭州云脑科技有限公司</td>\n",
       "      <td>云脑科技</td>\n",
       "      <td>15-50人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>A轮</td>\n",
       "      <td>15k-30k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>3898857</td>\n",
       "      <td>职位描述：【岗位职责】1、收集和整理公司运营数据、竞品数据、行业数据，解读趋势变化和异常波动...</td>\n",
       "      <td>fenxi</td>\n",
       "      <td>1、收集和整理公司运营数据、竞品数据、行业数据，解读趋势变化和异常波动，撰写分析报告；2、针...</td>\n",
       "      <td>1、计算机、数学等理工科专业本科以上学历；2、思路清晰，逻辑性强，具有较强的业务理解能力和表...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city    companyFullName companyShortName companySize district education  \\\n",
       "0   北京  汇联金科信息技术（北京 )有限公司             汇联金科     50-150人      朝阳区        本科   \n",
       "1   北京    途家网网络技术（北京）有限公司              途家网   500-2000人      朝阳区        本科   \n",
       "2   北京         和信电子商务有限公司              和信贷    150-500人      朝阳区        大专   \n",
       "3   北京               京东金融             京东金融     2000人以上      大兴区        本科   \n",
       "4   北京         杭州云脑科技有限公司             云脑科技      15-50人      朝阳区        本科   \n",
       "\n",
       "  financeStage   salary workYear  positionId  \\\n",
       "0           A轮  10k-15k     3-5年     4295741   \n",
       "1        D轮及以上  15k-30k     3-5年     4505031   \n",
       "2         上市公司    6k-8k     3-5年     4507358   \n",
       "3         上市公司  14k-27k     3-5年     4505903   \n",
       "4           A轮  15k-30k     3-5年     3898857   \n",
       "\n",
       "                                              detail     kd  \\\n",
       "0  职位描述：工作职责：1. 根据业务实际需求，制定相应策略，完成深入的运营数据分析报告，对用户...  fenxi   \n",
       "1  职位描述：工作职责：1、通过SQL收集数据，分析流量、活动、订单等核心数据，形成可视化报表；...  fenxi   \n",
       "2  职位描述：岗位职责：1. 对数据敏感，善于发现业务中存在的问题，并给出优化建议；2.熟悉用户...  fenxi   \n",
       "3  职位描述：职责描述：1、负责定期编制金融集团合并报表，完成报表变动分析；          ...  fenxi   \n",
       "4  职位描述：【岗位职责】1、收集和整理公司运营数据、竞品数据、行业数据，解读趋势变化和异常波动...  fenxi   \n",
       "\n",
       "                                                task  \\\n",
       "0  1. 根据业务实际需求，制定相应策略，完成深入的运营数据分析报告，对用户活跃、留存、有效行为...   \n",
       "1  1、通过SQL收集数据，分析流量、活动、订单等核心数据，形成可视化报表；2、分析用户行为、特...   \n",
       "2  1. 对数据敏感，善于发现业务中存在的问题，并给出优化建议；2.熟悉用户生命周期管理建设，搭...   \n",
       "3  1、负责定期编制金融集团合并报表，完成报表变动分析；                    ...   \n",
       "4  1、收集和整理公司运营数据、竞品数据、行业数据，解读趋势变化和异常波动，撰写分析报告；2、针...   \n",
       "\n",
       "                                               skill  \n",
       "0  1. 本科及以上学历，经济、统计、数学、计算机等相关专业背景优先；2. 至少3年以上互联网金...  \n",
       "1  1、3年以上互联网数据经验2、逻辑能力强，擅长数据分析与需求调研3、有很强的数据调研分析能力...  \n",
       "2  1、 金融、统计、数学、计算机等专业优先；2、 熟练使用Excel、SQL、SPSS，能够使...  \n",
       "3  1、计算机、统计学、数学、数理统计等相关专业，本科以上学历，3年以上相关工作经验； 2、熟练...  \n",
       "4  1、计算机、数学等理工科专业本科以上学历；2、思路清晰，逻辑性强，具有较强的业务理解能力和表...  "
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- not good the split part, keep the sub data to dig currently, if there's time later, revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_clean_sub = data_all_clean[~pd.isna(data_all_clean['task'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>companyFullName</th>\n",
       "      <th>companyShortName</th>\n",
       "      <th>companySize</th>\n",
       "      <th>district</th>\n",
       "      <th>education</th>\n",
       "      <th>financeStage</th>\n",
       "      <th>salary</th>\n",
       "      <th>workYear</th>\n",
       "      <th>positionId</th>\n",
       "      <th>detail</th>\n",
       "      <th>kd</th>\n",
       "      <th>task</th>\n",
       "      <th>skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>北京</td>\n",
       "      <td>东峡大通（北京）管理咨询有限公司</td>\n",
       "      <td>ofo</td>\n",
       "      <td>2000人以上</td>\n",
       "      <td>海淀区</td>\n",
       "      <td>本科</td>\n",
       "      <td>D轮及以上</td>\n",
       "      <td>17k-34k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>4444515</td>\n",
       "      <td>职位描述：工作职责:1. 监测重要业务指标数据变化，分析变化趋势和原因，并形成周期性报告2....</td>\n",
       "      <td>fenxi</td>\n",
       "      <td>1. 监测重要业务指标数据变化，分析变化趋势和原因，并形成周期性报告2. 建立业务健康度模型...</td>\n",
       "      <td>1硕士学位；数学，应用经济学，统计学等相关专业优先</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>北京</td>\n",
       "      <td>达飞云贷科技（北京）有限公司</td>\n",
       "      <td>达飞云贷</td>\n",
       "      <td>2000人以上</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>不需要融资</td>\n",
       "      <td>15k-25k</td>\n",
       "      <td>3-5年</td>\n",
       "      <td>3754688</td>\n",
       "      <td>职位描述：岗位职责：1、调研、分析业务部门数据需求；2、发现运营问题，进行深度专题分析，形成...</td>\n",
       "      <td>fenxi</td>\n",
       "      <td>1、调研、分析业务部门数据需求；2、发现运营问题，进行深度专题分析，形成结论并独立撰写分析报...</td>\n",
       "      <td>1、本科学历，统计学、计量经济学或者数学专业优先；2、精通Excel、熟练使用R、pytho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city   companyFullName companyShortName companySize district education  \\\n",
       "388   北京  东峡大通（北京）管理咨询有限公司              ofo     2000人以上      海淀区        本科   \n",
       "326   北京    达飞云贷科技（北京）有限公司             达飞云贷     2000人以上      朝阳区        本科   \n",
       "\n",
       "    financeStage   salary workYear  positionId  \\\n",
       "388        D轮及以上  17k-34k     3-5年     4444515   \n",
       "326        不需要融资  15k-25k     3-5年     3754688   \n",
       "\n",
       "                                                detail     kd  \\\n",
       "388  职位描述：工作职责:1. 监测重要业务指标数据变化，分析变化趋势和原因，并形成周期性报告2....  fenxi   \n",
       "326  职位描述：岗位职责：1、调研、分析业务部门数据需求；2、发现运营问题，进行深度专题分析，形成...  fenxi   \n",
       "\n",
       "                                                  task  \\\n",
       "388  1. 监测重要业务指标数据变化，分析变化趋势和原因，并形成周期性报告2. 建立业务健康度模型...   \n",
       "326  1、调研、分析业务部门数据需求；2、发现运营问题，进行深度专题分析，形成结论并独立撰写分析报...   \n",
       "\n",
       "                                                 skill  \n",
       "388                          1硕士学位；数学，应用经济学，统计学等相关专业优先  \n",
       "326  1、本科学历，统计学、计量经济学或者数学专业优先；2、精通Excel、熟练使用R、pytho...  "
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_clean_sub.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_all_clean_sub[data_all_clean_sub['kd'] == 'fenxi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_all_clean_sub[data_all_clean_sub['kd'] == 'wajue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add salary_avg column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_all_clean_sub['salary_low'] = data_all_clean_sub.salary.str.extract('(.*).-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary_low.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_all_clean_sub['salary_up'] = data_all_clean_sub.salary.str.extract('-(.*).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_all_clean_sub['salary_low'] = data_all_clean_sub['salary_low'].astype(float)\n",
    "data_all_clean_sub['salary_up'] = data_all_clean_sub['salary_up'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data_all_clean_sub['salary_avg'] = (data_all_clean_sub['salary_low'] + \n",
    "                                    data_all_clean_sub['salary_up'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_clean_sub.to_csv('data_all_clean_sub.csv', encoding=\"utf_8_sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kd     workYear\n",
       "fenxi  1-3年         40.0\n",
       "       1年以下          7.0\n",
       "       3-5年         60.0\n",
       "       5-10年       100.0\n",
       "       不限           40.0\n",
       "wajue  1-3年         50.0\n",
       "       1年以下         20.0\n",
       "       3-5年        100.0\n",
       "       5-10年        80.0\n",
       "       不限           60.0\n",
       "Name: salary_up, dtype: float64"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_clean_sub.groupby(['kd','workYear']).salary_up.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kd     workYear\n",
       "fenxi  1-3年         6.0\n",
       "       1年以下         7.0\n",
       "       3-5年         8.0\n",
       "       5-10年       15.0\n",
       "       不限           8.0\n",
       "wajue  1-3年        12.0\n",
       "       1年以下        19.0\n",
       "       3-5年         5.0\n",
       "       5-10年       25.0\n",
       "       不限           6.0\n",
       "Name: salary_up, dtype: float64"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_clean_sub.groupby(['kd','workYear']).salary_up.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>companyFullName</th>\n",
       "      <th>companyShortName</th>\n",
       "      <th>companySize</th>\n",
       "      <th>district</th>\n",
       "      <th>education</th>\n",
       "      <th>financeStage</th>\n",
       "      <th>salary</th>\n",
       "      <th>workYear</th>\n",
       "      <th>positionId</th>\n",
       "      <th>detail</th>\n",
       "      <th>kd</th>\n",
       "      <th>task</th>\n",
       "      <th>skill</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_up</th>\n",
       "      <th>salary_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>北京</td>\n",
       "      <td>北京思维造物信息科技有限公司</td>\n",
       "      <td>罗辑思维</td>\n",
       "      <td>150-500人</td>\n",
       "      <td>朝阳区</td>\n",
       "      <td>本科</td>\n",
       "      <td>B轮</td>\n",
       "      <td>5k-10k</td>\n",
       "      <td>不限</td>\n",
       "      <td>4501239</td>\n",
       "      <td>职位描述：职责描述：1.负责大数据平台的建设和数据开发工作2.负责使用数据分析、挖掘相关算法...</td>\n",
       "      <td>wajue</td>\n",
       "      <td>1.负责大数据平台的建设和数据开发工作2.负责使用数据分析、挖掘相关算法和工具进行产品开发和...</td>\n",
       "      <td>1.计算机相关专业本科及以上学历，有扎实的机器学习/数据挖掘/自然语言处理基础2.每周保证4...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    city companyFullName companyShortName companySize district education  \\\n",
       "572   北京  北京思维造物信息科技有限公司             罗辑思维    150-500人      朝阳区        本科   \n",
       "\n",
       "    financeStage  salary workYear  positionId  \\\n",
       "572           B轮  5k-10k       不限     4501239   \n",
       "\n",
       "                                                detail     kd  \\\n",
       "572  职位描述：职责描述：1.负责大数据平台的建设和数据开发工作2.负责使用数据分析、挖掘相关算法...  wajue   \n",
       "\n",
       "                                                  task  \\\n",
       "572  1.负责大数据平台的建设和数据开发工作2.负责使用数据分析、挖掘相关算法和工具进行产品开发和...   \n",
       "\n",
       "                                                 skill  salary_low  salary_up  \\\n",
       "572  1.计算机相关专业本科及以上学历，有扎实的机器学习/数据挖掘/自然语言处理基础2.每周保证4...         5.0       10.0   \n",
       "\n",
       "     salary_avg  \n",
       "572         7.5  "
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_clean_sub[(data_all_clean_sub['salary_low'] == 5) & (data_all_clean_sub['kd'] == 'wajue')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_all_clean_sub['salary_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "- will use tableau to do basic comparing\n",
    "- use ntlk, wordcloud to do basic wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use ntlk, wordcloud to do basic wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_fenxi = data_all_clean_sub[data_all_clean_sub['kd'] == 'fenxi']['skill'].str.cat(sep = ' ')\n",
    "task_fenxi = data_all_clean_sub[data_all_clean_sub['kd'] == 'fenxi']['task'].str.cat(sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76442"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skill_fenxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_wajue = data_all_clean_sub[data_all_clean_sub['kd'] == 'wajue']['skill'].str.cat(sep = ' ')\n",
    "task_wajue = data_all_clean_sub[data_all_clean_sub['kd'] == 'wajue']['task'].str.cat(sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71749"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skill_wajue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_fenxi_cut = jieba.cut(skill_fenxi)\n",
    "skill_wajue_cut = jieba.cut(skill_wajue)\n",
    "task_fenxi_cut = jieba.cut(task_fenxi)\n",
    "task_wajue_cut = jieba.cut(task_wajue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_fenxi_cut_text = \",\".join(skill_fenxi_cut)\n",
    "skill_wajue_cut_text = \",\".join(skill_wajue_cut)\n",
    "task_fenxi_cut_text = \",\".join(task_fenxi_cut)\n",
    "task_wajue_cut_text = \",\".join(task_wajue_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"/\".join(skill_fenxi_cut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_table('stopwords.dat')\n",
    "stopwords.columns = ['stopwords']\n",
    "stopwords = stopwords.stopwords.str.cat(sep = ',')\n",
    "stopwords = stopwords + ',1,2,3,4,5,6,7,8,9,10,，,、, ,；,\\xa0,。,：,）,（,:,+,】,【,;,—,“,”,「,」,-,．,&,！'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(stopwords, text):\n",
    "    text_list = text.split(',')\n",
    "    filter_list = [word for word in text_list if word not in stopwords]\n",
    "    filter_text = ','.join(filter_list)\n",
    "    return filter_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_freq_list(text):\n",
    "    stopwords_mini = 'A, APP, L, O, P, PIG, COM, HTTP, HTTPS, ISHUMEI, WWW'\n",
    "    out = re.findall('([a-zA-Z]*)', text)\n",
    "    out = [loop.upper() for loop in out if loop.upper() not in stopwords_mini]\n",
    "    out = ','.join(out)\n",
    "    out = out.split(',')\n",
    "    out_freq = nltk.FreqDist(out)\n",
    "    for loop in list(out_freq.keys()):\n",
    "        if out_freq[loop] == 1:\n",
    "            del(out_freq[loop])\n",
    "    return out_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeWordCloud():\n",
    "    def __init__(self, text, mask = None, font = 'HYQiHei-25J.ttf', out_name = 'skill_fenxi.jpg'):\n",
    "        self.text = text\n",
    "        self.mask = mask\n",
    "        self.font = font\n",
    "        self.out_name = out_name\n",
    "    def make_cloud(self, max_words = 1000):\n",
    "        cur_path = path.abspath('.')\n",
    "        if self.mask == None:\n",
    "            color_mask = None\n",
    "        else:\n",
    "            color_mask = imread(self.mask)\n",
    "        wc = WordCloud(font_path=self.font, background_color=\"white\", \n",
    "               max_words=max_words, mask=color_mask, random_state=42, max_font_size=100,width=500, height=350)\n",
    "        cloud = wc.generate_from_frequencies(self.text)\n",
    "        if self.mask == None:\n",
    "            pass\n",
    "        else:\n",
    "            img_colors = ImageColorGenerator(color_mask) \n",
    "            cloud.recolor(color_func = img_colors)\n",
    "        cloud.to_file(path.join(cur_path, self.out_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_text = filter_stopwords(stopwords, skill_fenxi_cut_text)\n",
    "skill_fenxi_freq = make_freq_list(filter_text)\n",
    "skill_fenxi_cloud = MakeWordCloud(skill_fenxi_freq, out_name='skill_fenxi.jpg')\n",
    "skill_fenxi_cloud.make_cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_text = filter_stopwords(stopwords, skill_wajue_cut_text)\n",
    "skill_wajue_freq = make_freq_list(filter_text)\n",
    "skill_wajue_cloud = MakeWordCloud(skill_wajue_freq, out_name='skill_wajue.jpg')\n",
    "skill_wajue_cloud.make_cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "filter_text = filter_stopwords(stopwords, task_fenxi_cut_text)\n",
    "task_fenxi_freq = nltk.FreqDist(filter_text.split(','))\n",
    "task_fenxi_cloud = MakeWordCloud(task_fenxi_freq, mask = 'zhichangren.jpg', out_name='task_fenxi.jpg')\n",
    "task_fenxi_cloud.make_cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "filter_text = filter_stopwords(stopwords, task_wajue_cut_text)\n",
    "task_wajue_freq = nltk.FreqDist(filter_text.split(','))\n",
    "task_wajue_cloud = MakeWordCloud(task_wajue_freq, mask = 'zhichangren.jpg', out_name='task_wajue.jpg')\n",
    "task_wajue_cloud.make_cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
